import streamlit as st
from PIL import Image
import pandas as pd
import torch
import numpy as np
from torchvision import transforms
from importlib import import_module
import os

#ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
def load_model(saved_model, device): 
    model_class = "EfficientNet_b2"

    #ë™ì ìœ¼ë¡œ model.pyë¥¼ importí•˜ê³  ì›í•˜ëŠ” classë¥¼ ê°€ì ¸ì˜´
    model_cls = getattr(import_module("model"), model_class) 
    model = model_cls(18)

    # ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•œë‹¤.
    model_path = os.path.join(saved_model, model_class+"_best.pth")
    model.load_state_dict(torch.load(model_path, map_location=device))

    return model

# ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ì— ë§ê²Œ ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
def preprocess_image(image):
    preprocess = transforms.Compose([
        transforms.Resize((260, 260)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.548, 0.504, 0.479], std=[0.237, 0.247, 0.246]),
    ])
    img = preprocess(image)
    img = img.unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    return img

mask_mapping = {
    0: 'ì˜¬ë°”ë¥¸ ë§ˆìŠ¤í¬ ì°©ìš©ì…ë‹ˆë‹¤ğŸ˜Š',
    1: 'ì˜ëª»ëœ ë§ˆìŠ¤í¬ ì°©ìš©ì…ë‹ˆë‹¤ğŸ˜¢',
    2: 'ë§ˆìŠ¤í¬ë¥¼ ì°©ìš©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ğŸ˜¶'
}

gender_mapping = {
    0: 'ë‚¨ì„±',
    1: 'ì—¬ì„±'
}

age_mapping = {
    0: '10ëŒ€~20ëŒ€',
    1: '30ëŒ€~50ëŒ€',
    2: '60ëŒ€ ì´ìƒ'
}

#ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
# CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸
use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
model = load_model("./model", device).to(device)
model.eval()

# Streamlit ì•± êµ¬ì„±
st.title("ğŸ˜·Mask Classification")
st.sidebar.header("ì›í•˜ëŠ” ì‚¬ì§„ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”")
st.sidebar.write("ì‚¬ëŒì˜ ì •ë©´ ëª¨ìŠµì´ ì‚¬ì§„ì„ í†µí•´ **ë‚˜ì´**ì™€ **ì„±ë³„**, **ë§ˆìŠ¤í¬ ì°©ìš© ì—¬ë¶€**ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.")
st.sidebar.markdown("")

# íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥
uploaded_file = st.sidebar.file_uploader("íŒŒì¼ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    try:
        image = Image.open(uploaded_file)
    except Exception as e:
        st.error("ì´ë¯¸ì§€ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
    else:
        # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ í‘œì‹œ
        image = Image.open(uploaded_file)
        st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=False, width=250)

        # ëª¨ë¸ ì˜ˆì¸¡
        with st.spinner("ì´ë¯¸ì§€ ë¶„ë¥˜ ì¤‘..."): #ì—°ì‚°ì´ ì§„í–‰ë˜ëŠ” ë„ì¤‘ ë©”ì„¸ì§€ ì¶œë ¥
            img_array = preprocess_image(image)
            with torch.no_grad():
                predictions = model(img_array)
            prediction = torch.argmax(predictions).item()

            # classë³„ ë¶„ë¥˜
            mask_label = (prediction // 6) % 3
            gender_label = (prediction // 3) % 2
            age_label = prediction % 3

            mask = mask_mapping.get(mask_label, "Unknown")
            gender = gender_mapping.get(gender_label, "Unknown")
            age = age_mapping.get(age_label,"Unknown")

            st.balloons() #íŠ¹ìˆ˜íš¨ê³¼
        
        # ê²°ê³¼ ì¶œë ¥
        st.markdown("### ë¶„ë¥˜ ê²°ê³¼", unsafe_allow_html=True)
        st.write(f"{age} {gender}ì…ë‹ˆë‹¤. {mask}")